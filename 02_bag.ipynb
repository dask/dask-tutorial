{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dask_horizontal.svg\" align=\"right\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag: Parallel Lists for semi-structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask-bag excels in processing data that can be represented as a sequence of arbitrary inputs. We'll refer to this as \"messy\" data, because it can contain complex nested structures, missing fields, mixtures of data types, etc. The *functional* programming style fits very nicely with standard Python iteration, such as can be found in the `itertools` module.\n",
    "\n",
    "Messy data is often encountered at the beginning of data processing pipelines when large volumes of raw data are first consumed. The initial set of data might be JSON, CSV, XML, or any other format that does not enforce strict structure and datatypes.\n",
    "For this reason, the initial data massaging and processing is often done with Python `list`s, `dict`s, and `set`s.\n",
    "\n",
    "These core data structures are optimized for general-purpose storage and processing.  Adding streaming computation with iterators/generator expressions or libraries like `itertools` or [`toolz`](https://toolz.readthedocs.io/en/latest/) let us process large volumes in a small space.  If we combine this with parallel processing then we can churn through a fair amount of data.\n",
    "\n",
    "Dask.bag is a high level Dask collection to automate common workloads of this form.  In a nutshell\n",
    "\n",
    "    dask.bag = map, filter, toolz + parallel execution\n",
    "    \n",
    "**Related Documentation**\n",
    "\n",
    "* [Bag documentation](https://docs.dask.org/en/latest/bag.html)\n",
    "* [Bag screencast](https://youtu.be/-qIiJ1XtSv0)\n",
    "* [Bag API](https://docs.dask.org/en/latest/bag-api.html)\n",
    "* [Bag examples](https://examples.dask.org/bag.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:23.186390Z",
     "iopub.status.busy": "2022-04-20T16:12:23.186149Z",
     "iopub.status.idle": "2022-04-20T16:12:23.973288Z",
     "shell.execute_reply": "2022-04-20T16:12:23.972426Z"
    }
   },
   "outputs": [],
   "source": [
    "%run prep.py -d accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll use the distributed scheduler. Schedulers will be explained in depth [later](05_distributed.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:23.977338Z",
     "iopub.status.busy": "2022-04-20T16:12:23.977118Z",
     "iopub.status.idle": "2022-04-20T16:12:26.888454Z",
     "shell.execute_reply": "2022-04-20T16:12:26.887363Z"
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a `Bag` from a Python sequence, from files, from data on S3, etc.\n",
    "We demonstrate using `.take()` to show elements of the data. (Doing `.take(1)` results in a tuple with one element)\n",
    "\n",
    "Note that the data are partitioned into blocks, and there are many items per block. In the first example, the two partitions contain five elements each, and in the following two, each file is partitioned into one or more bytes blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:26.893210Z",
     "iopub.status.busy": "2022-04-20T16:12:26.892698Z",
     "iopub.status.idle": "2022-04-20T16:12:27.303999Z",
     "shell.execute_reply": "2022-04-20T16:12:27.302980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each element is an integer\n",
    "import dask.bag as db\n",
    "b = db.from_sequence([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], npartitions=2)\n",
    "b.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:27.309591Z",
     "iopub.status.busy": "2022-04-20T16:12:27.309395Z",
     "iopub.status.idle": "2022-04-20T16:12:27.452865Z",
     "shell.execute_reply": "2022-04-20T16:12:27.452100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\"id\": 0, \"name\": \"Sarah\", \"transactions\": [{\"transaction-id\": 6861, \"amount\": 206}]}\\n',)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each element is a text file, where each line is a JSON object\n",
    "# note that the compression is handled automatically\n",
    "import os\n",
    "b = db.read_text(os.path.join('data', 'accounts.*.json.gz'))\n",
    "b.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:27.456279Z",
     "iopub.status.busy": "2022-04-20T16:12:27.456020Z",
     "iopub.status.idle": "2022-04-20T16:12:27.461993Z",
     "shell.execute_reply": "2022-04-20T16:12:27.461447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://dask-data/nyc-taxi/2015/yellow_tripdata_2015-01.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edit sources.py to configure source locations\n",
    "import sources\n",
    "sources.bag_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:27.465558Z",
     "iopub.status.busy": "2022-04-20T16:12:27.465208Z",
     "iopub.status.idle": "2022-04-20T16:12:28.322657Z",
     "shell.execute_reply": "2022-04-20T16:12:28.321587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,pickup_longitude,pickup_latitude,RateCodeID,store_and_fwd_flag,dropoff_longitude,dropoff_latitude,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount\\n',)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires `s3fs` library\n",
    "# each partition is a remote CSV text file\n",
    "b = db.read_text(sources.bag_url,\n",
    "                 storage_options={'anon': True})\n",
    "b.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Bag` objects hold the standard functional API found in projects like the Python standard library, `toolz`, or `pyspark`, including `map`, `filter`, `groupby`, etc..\n",
    "\n",
    "Operations on `Bag` objects create new bags.  Call the `.compute()` method to trigger execution, as we saw for `Delayed` objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:28.326120Z",
     "iopub.status.busy": "2022-04-20T16:12:28.325653Z",
     "iopub.status.idle": "2022-04-20T16:12:28.337015Z",
     "shell.execute_reply": "2022-04-20T16:12:28.336343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<lambda, npartitions=10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_even(n):\n",
    "    return n % 2 == 0\n",
    "\n",
    "b = db.from_sequence([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "c = b.filter(is_even).map(lambda x: x ** 2)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:28.340295Z",
     "iopub.status.busy": "2022-04-20T16:12:28.340077Z",
     "iopub.status.idle": "2022-04-20T16:12:28.537584Z",
     "shell.execute_reply": "2022-04-20T16:12:28.536804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 16, 36, 64, 100]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blocking form: wait for completion (which is very fast in this case)\n",
    "c.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Accounts JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a fake dataset of gzipped JSON data in your data directory.  This is like the example used in the `DataFrame` example we will see later, except that it has bundled up all of the entries for each individual `id` into a single record.  This is similar to data that you might collect off of a document store database or a web API.\n",
    "\n",
    "Each line is a JSON encoded dictionary with the following keys\n",
    "\n",
    "*  id: Unique identifier of the customer\n",
    "*  name: Name of the customer\n",
    "*  transactions: List of `transaction-id`, `amount` pairs, one for each transaction for the customer in that file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:28.541233Z",
     "iopub.status.busy": "2022-04-20T16:12:28.540850Z",
     "iopub.status.idle": "2022-04-20T16:12:28.707867Z",
     "shell.execute_reply": "2022-04-20T16:12:28.707075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\"id\": 0, \"name\": \"Sarah\", \"transactions\": [{\"transaction-id\": 6861, \"amount\": 206}]}\\n',\n",
       " '{\"id\": 1, \"name\": \"Jerry\", \"transactions\": [{\"transaction-id\": 743, \"amount\": 796}, {\"transaction-id\": 2081, \"amount\": 761}, {\"transaction-id\": 3492, \"amount\": 859}, {\"transaction-id\": 5980, \"amount\": 885}, {\"transaction-id\": 6285, \"amount\": 862}, {\"transaction-id\": 8658, \"amount\": 782}]}\\n',\n",
       " '{\"id\": 2, \"name\": \"Norbert\", \"transactions\": [{\"transaction-id\": 40, \"amount\": 118}, {\"transaction-id\": 214, \"amount\": 92}, {\"transaction-id\": 1280, \"amount\": 112}, {\"transaction-id\": 2108, \"amount\": 111}, {\"transaction-id\": 2595, \"amount\": 103}, {\"transaction-id\": 2791, \"amount\": 101}, {\"transaction-id\": 2877, \"amount\": 87}, {\"transaction-id\": 3188, \"amount\": 124}, {\"transaction-id\": 3544, \"amount\": 108}, {\"transaction-id\": 3689, \"amount\": 106}, {\"transaction-id\": 3964, \"amount\": 115}, {\"transaction-id\": 4347, \"amount\": 123}, {\"transaction-id\": 4616, \"amount\": 109}, {\"transaction-id\": 5228, \"amount\": 87}, {\"transaction-id\": 5755, \"amount\": 92}, {\"transaction-id\": 5789, \"amount\": 117}, {\"transaction-id\": 7039, \"amount\": 110}, {\"transaction-id\": 8380, \"amount\": 108}, {\"transaction-id\": 8634, \"amount\": 109}, {\"transaction-id\": 8997, \"amount\": 116}, {\"transaction-id\": 9114, \"amount\": 97}, {\"transaction-id\": 9171, \"amount\": 114}, {\"transaction-id\": 9379, \"amount\": 91}, {\"transaction-id\": 9517, \"amount\": 117}, {\"transaction-id\": 9869, \"amount\": 141}]}\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = os.path.join('data', 'accounts.*.json.gz')\n",
    "lines = db.read_text(filename)\n",
    "lines.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data comes out of the file as lines of text. Notice that file decompression happened automatically. We can make this data look more reasonable by mapping the `json.loads` function onto our bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:28.711637Z",
     "iopub.status.busy": "2022-04-20T16:12:28.711249Z",
     "iopub.status.idle": "2022-04-20T16:12:28.744814Z",
     "shell.execute_reply": "2022-04-20T16:12:28.744086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 0,\n",
       "  'name': 'Sarah',\n",
       "  'transactions': [{'transaction-id': 6861, 'amount': 206}]},\n",
       " {'id': 1,\n",
       "  'name': 'Jerry',\n",
       "  'transactions': [{'transaction-id': 743, 'amount': 796},\n",
       "   {'transaction-id': 2081, 'amount': 761},\n",
       "   {'transaction-id': 3492, 'amount': 859},\n",
       "   {'transaction-id': 5980, 'amount': 885},\n",
       "   {'transaction-id': 6285, 'amount': 862},\n",
       "   {'transaction-id': 8658, 'amount': 782}]},\n",
       " {'id': 2,\n",
       "  'name': 'Norbert',\n",
       "  'transactions': [{'transaction-id': 40, 'amount': 118},\n",
       "   {'transaction-id': 214, 'amount': 92},\n",
       "   {'transaction-id': 1280, 'amount': 112},\n",
       "   {'transaction-id': 2108, 'amount': 111},\n",
       "   {'transaction-id': 2595, 'amount': 103},\n",
       "   {'transaction-id': 2791, 'amount': 101},\n",
       "   {'transaction-id': 2877, 'amount': 87},\n",
       "   {'transaction-id': 3188, 'amount': 124},\n",
       "   {'transaction-id': 3544, 'amount': 108},\n",
       "   {'transaction-id': 3689, 'amount': 106},\n",
       "   {'transaction-id': 3964, 'amount': 115},\n",
       "   {'transaction-id': 4347, 'amount': 123},\n",
       "   {'transaction-id': 4616, 'amount': 109},\n",
       "   {'transaction-id': 5228, 'amount': 87},\n",
       "   {'transaction-id': 5755, 'amount': 92},\n",
       "   {'transaction-id': 5789, 'amount': 117},\n",
       "   {'transaction-id': 7039, 'amount': 110},\n",
       "   {'transaction-id': 8380, 'amount': 108},\n",
       "   {'transaction-id': 8634, 'amount': 109},\n",
       "   {'transaction-id': 8997, 'amount': 116},\n",
       "   {'transaction-id': 9114, 'amount': 97},\n",
       "   {'transaction-id': 9171, 'amount': 114},\n",
       "   {'transaction-id': 9379, 'amount': 91},\n",
       "   {'transaction-id': 9517, 'amount': 117},\n",
       "   {'transaction-id': 9869, 'amount': 141}]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "js = lines.map(json.loads)\n",
    "# take: inspect first few elements\n",
    "js.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we parse our JSON data into proper Python objects (`dict`s, `list`s, etc.) we can perform more interesting queries by creating small Python functions to run on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:28.748334Z",
     "iopub.status.busy": "2022-04-20T16:12:28.748118Z",
     "iopub.status.idle": "2022-04-20T16:12:28.793231Z",
     "shell.execute_reply": "2022-04-20T16:12:28.790831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 3,\n",
       "  'name': 'Alice',\n",
       "  'transactions': [{'transaction-id': 790, 'amount': 1063},\n",
       "   {'transaction-id': 4060, 'amount': 1103},\n",
       "   {'transaction-id': 4577, 'amount': 1077},\n",
       "   {'transaction-id': 6531, 'amount': 1166},\n",
       "   {'transaction-id': 6907, 'amount': 1126},\n",
       "   {'transaction-id': 7034, 'amount': 1087},\n",
       "   {'transaction-id': 9459, 'amount': 1011}]},\n",
       " {'id': 18,\n",
       "  'name': 'Alice',\n",
       "  'transactions': [{'transaction-id': 91, 'amount': 93},\n",
       "   {'transaction-id': 220, 'amount': 178},\n",
       "   {'transaction-id': 261, 'amount': 65},\n",
       "   {'transaction-id': 265, 'amount': 176},\n",
       "   {'transaction-id': 374, 'amount': 175},\n",
       "   {'transaction-id': 629, 'amount': 288},\n",
       "   {'transaction-id': 781, 'amount': 137},\n",
       "   {'transaction-id': 873, 'amount': 186},\n",
       "   {'transaction-id': 992, 'amount': 194},\n",
       "   {'transaction-id': 1032, 'amount': 242},\n",
       "   {'transaction-id': 1879, 'amount': 217},\n",
       "   {'transaction-id': 2017, 'amount': 155},\n",
       "   {'transaction-id': 2387, 'amount': 231},\n",
       "   {'transaction-id': 2460, 'amount': 117},\n",
       "   {'transaction-id': 2621, 'amount': 247},\n",
       "   {'transaction-id': 2759, 'amount': 188},\n",
       "   {'transaction-id': 3527, 'amount': 150},\n",
       "   {'transaction-id': 3749, 'amount': 169},\n",
       "   {'transaction-id': 4129, 'amount': 196},\n",
       "   {'transaction-id': 4513, 'amount': 120},\n",
       "   {'transaction-id': 4969, 'amount': 141},\n",
       "   {'transaction-id': 5014, 'amount': 210},\n",
       "   {'transaction-id': 5096, 'amount': 311},\n",
       "   {'transaction-id': 5322, 'amount': 194},\n",
       "   {'transaction-id': 5363, 'amount': 178},\n",
       "   {'transaction-id': 5459, 'amount': 133},\n",
       "   {'transaction-id': 6020, 'amount': 148},\n",
       "   {'transaction-id': 6468, 'amount': 123},\n",
       "   {'transaction-id': 8125, 'amount': 128},\n",
       "   {'transaction-id': 8629, 'amount': 148},\n",
       "   {'transaction-id': 9508, 'amount': 200},\n",
       "   {'transaction-id': 9792, 'amount': 193},\n",
       "   {'transaction-id': 9873, 'amount': 124}]},\n",
       " {'id': 54,\n",
       "  'name': 'Alice',\n",
       "  'transactions': [{'transaction-id': 249, 'amount': 688},\n",
       "   {'transaction-id': 635, 'amount': 706},\n",
       "   {'transaction-id': 693, 'amount': 645},\n",
       "   {'transaction-id': 746, 'amount': 755},\n",
       "   {'transaction-id': 1195, 'amount': 635},\n",
       "   {'transaction-id': 1606, 'amount': 700},\n",
       "   {'transaction-id': 2092, 'amount': 632},\n",
       "   {'transaction-id': 3190, 'amount': 655},\n",
       "   {'transaction-id': 3684, 'amount': 688},\n",
       "   {'transaction-id': 4049, 'amount': 676},\n",
       "   {'transaction-id': 4122, 'amount': 677},\n",
       "   {'transaction-id': 4266, 'amount': 660},\n",
       "   {'transaction-id': 5211, 'amount': 610},\n",
       "   {'transaction-id': 6510, 'amount': 676},\n",
       "   {'transaction-id': 6820, 'amount': 690},\n",
       "   {'transaction-id': 7720, 'amount': 680},\n",
       "   {'transaction-id': 7783, 'amount': 635},\n",
       "   {'transaction-id': 7889, 'amount': 698},\n",
       "   {'transaction-id': 7949, 'amount': 652},\n",
       "   {'transaction-id': 8382, 'amount': 651},\n",
       "   {'transaction-id': 8898, 'amount': 697},\n",
       "   {'transaction-id': 9166, 'amount': 715},\n",
       "   {'transaction-id': 9835, 'amount': 647}]},\n",
       " {'id': 88,\n",
       "  'name': 'Alice',\n",
       "  'transactions': [{'transaction-id': 23, 'amount': 315},\n",
       "   {'transaction-id': 149, 'amount': 293},\n",
       "   {'transaction-id': 494, 'amount': 327},\n",
       "   {'transaction-id': 685, 'amount': 298},\n",
       "   {'transaction-id': 849, 'amount': 327},\n",
       "   {'transaction-id': 1409, 'amount': 272},\n",
       "   {'transaction-id': 2436, 'amount': 306},\n",
       "   {'transaction-id': 3947, 'amount': 289},\n",
       "   {'transaction-id': 4294, 'amount': 279},\n",
       "   {'transaction-id': 4545, 'amount': 323},\n",
       "   {'transaction-id': 5131, 'amount': 282},\n",
       "   {'transaction-id': 5534, 'amount': 302},\n",
       "   {'transaction-id': 5868, 'amount': 292},\n",
       "   {'transaction-id': 6370, 'amount': 283},\n",
       "   {'transaction-id': 6449, 'amount': 270},\n",
       "   {'transaction-id': 6464, 'amount': 261},\n",
       "   {'transaction-id': 6960, 'amount': 303},\n",
       "   {'transaction-id': 7442, 'amount': 296},\n",
       "   {'transaction-id': 7808, 'amount': 318},\n",
       "   {'transaction-id': 8218, 'amount': 315},\n",
       "   {'transaction-id': 8293, 'amount': 266},\n",
       "   {'transaction-id': 8870, 'amount': 308},\n",
       "   {'transaction-id': 9251, 'amount': 303},\n",
       "   {'transaction-id': 9495, 'amount': 334},\n",
       "   {'transaction-id': 9522, 'amount': 311},\n",
       "   {'transaction-id': 9557, 'amount': 286},\n",
       "   {'transaction-id': 9678, 'amount': 287},\n",
       "   {'transaction-id': 9784, 'amount': 283}]},\n",
       " {'id': 176,\n",
       "  'name': 'Alice',\n",
       "  'transactions': [{'transaction-id': 1150, 'amount': 1772},\n",
       "   {'transaction-id': 1664, 'amount': 1589},\n",
       "   {'transaction-id': 2060, 'amount': 1550},\n",
       "   {'transaction-id': 2576, 'amount': 1461},\n",
       "   {'transaction-id': 3111, 'amount': 1549},\n",
       "   {'transaction-id': 3814, 'amount': 1609},\n",
       "   {'transaction-id': 4796, 'amount': 1585},\n",
       "   {'transaction-id': 8093, 'amount': 1711},\n",
       "   {'transaction-id': 8645, 'amount': 1818},\n",
       "   {'transaction-id': 9473, 'amount': 1661}]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter: keep only some elements of the sequence\n",
    "js.filter(lambda record: record['name'] == 'Alice').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:28.796917Z",
     "iopub.status.busy": "2022-04-20T16:12:28.796725Z",
     "iopub.status.idle": "2022-04-20T16:12:28.838791Z",
     "shell.execute_reply": "2022-04-20T16:12:28.837120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'name': 'Alice', 'count': 7},\n",
       " {'name': 'Alice', 'count': 33},\n",
       " {'name': 'Alice', 'count': 23},\n",
       " {'name': 'Alice', 'count': 28},\n",
       " {'name': 'Alice', 'count': 10})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_transactions(d):\n",
    "    return {'name': d['name'], 'count': len(d['transactions'])}\n",
    "\n",
    "# map: apply a function to each element\n",
    "(js.filter(lambda record: record['name'] == 'Alice')\n",
    "   .map(count_transactions)\n",
    "   .take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:28.842644Z",
     "iopub.status.busy": "2022-04-20T16:12:28.842322Z",
     "iopub.status.idle": "2022-04-20T16:12:28.879756Z",
     "shell.execute_reply": "2022-04-20T16:12:28.878747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 33, 23, 28, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pluck: select a field, as from a dictionary, element[field]\n",
    "(js.filter(lambda record: record['name'] == 'Alice')\n",
    "   .map(count_transactions)\n",
    "   .pluck('count')\n",
    "   .take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:28.883681Z",
     "iopub.status.busy": "2022-04-20T16:12:28.883341Z",
     "iopub.status.idle": "2022-04-20T16:12:29.452640Z",
     "shell.execute_reply": "2022-04-20T16:12:29.451651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.586666666666666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average number of transactions for all of the Alice entries\n",
    "(js.filter(lambda record: record['name'] == 'Alice')\n",
    "   .map(count_transactions)\n",
    "   .pluck('count')\n",
    "   .mean()\n",
    "   .compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `flatten` to de-nest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below we see the use of `.flatten()` to flatten results.  We compute the average amount for all transactions for all Alices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:29.456918Z",
     "iopub.status.busy": "2022-04-20T16:12:29.456023Z",
     "iopub.status.idle": "2022-04-20T16:12:29.495830Z",
     "shell.execute_reply": "2022-04-20T16:12:29.494955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'transaction-id': 790, 'amount': 1063},\n",
       "  {'transaction-id': 4060, 'amount': 1103},\n",
       "  {'transaction-id': 4577, 'amount': 1077},\n",
       "  {'transaction-id': 6531, 'amount': 1166},\n",
       "  {'transaction-id': 6907, 'amount': 1126},\n",
       "  {'transaction-id': 7034, 'amount': 1087},\n",
       "  {'transaction-id': 9459, 'amount': 1011}],\n",
       " [{'transaction-id': 91, 'amount': 93},\n",
       "  {'transaction-id': 220, 'amount': 178},\n",
       "  {'transaction-id': 261, 'amount': 65},\n",
       "  {'transaction-id': 265, 'amount': 176},\n",
       "  {'transaction-id': 374, 'amount': 175},\n",
       "  {'transaction-id': 629, 'amount': 288},\n",
       "  {'transaction-id': 781, 'amount': 137},\n",
       "  {'transaction-id': 873, 'amount': 186},\n",
       "  {'transaction-id': 992, 'amount': 194},\n",
       "  {'transaction-id': 1032, 'amount': 242},\n",
       "  {'transaction-id': 1879, 'amount': 217},\n",
       "  {'transaction-id': 2017, 'amount': 155},\n",
       "  {'transaction-id': 2387, 'amount': 231},\n",
       "  {'transaction-id': 2460, 'amount': 117},\n",
       "  {'transaction-id': 2621, 'amount': 247},\n",
       "  {'transaction-id': 2759, 'amount': 188},\n",
       "  {'transaction-id': 3527, 'amount': 150},\n",
       "  {'transaction-id': 3749, 'amount': 169},\n",
       "  {'transaction-id': 4129, 'amount': 196},\n",
       "  {'transaction-id': 4513, 'amount': 120},\n",
       "  {'transaction-id': 4969, 'amount': 141},\n",
       "  {'transaction-id': 5014, 'amount': 210},\n",
       "  {'transaction-id': 5096, 'amount': 311},\n",
       "  {'transaction-id': 5322, 'amount': 194},\n",
       "  {'transaction-id': 5363, 'amount': 178},\n",
       "  {'transaction-id': 5459, 'amount': 133},\n",
       "  {'transaction-id': 6020, 'amount': 148},\n",
       "  {'transaction-id': 6468, 'amount': 123},\n",
       "  {'transaction-id': 8125, 'amount': 128},\n",
       "  {'transaction-id': 8629, 'amount': 148},\n",
       "  {'transaction-id': 9508, 'amount': 200},\n",
       "  {'transaction-id': 9792, 'amount': 193},\n",
       "  {'transaction-id': 9873, 'amount': 124}],\n",
       " [{'transaction-id': 249, 'amount': 688},\n",
       "  {'transaction-id': 635, 'amount': 706},\n",
       "  {'transaction-id': 693, 'amount': 645},\n",
       "  {'transaction-id': 746, 'amount': 755},\n",
       "  {'transaction-id': 1195, 'amount': 635},\n",
       "  {'transaction-id': 1606, 'amount': 700},\n",
       "  {'transaction-id': 2092, 'amount': 632},\n",
       "  {'transaction-id': 3190, 'amount': 655},\n",
       "  {'transaction-id': 3684, 'amount': 688},\n",
       "  {'transaction-id': 4049, 'amount': 676},\n",
       "  {'transaction-id': 4122, 'amount': 677},\n",
       "  {'transaction-id': 4266, 'amount': 660},\n",
       "  {'transaction-id': 5211, 'amount': 610},\n",
       "  {'transaction-id': 6510, 'amount': 676},\n",
       "  {'transaction-id': 6820, 'amount': 690},\n",
       "  {'transaction-id': 7720, 'amount': 680},\n",
       "  {'transaction-id': 7783, 'amount': 635},\n",
       "  {'transaction-id': 7889, 'amount': 698},\n",
       "  {'transaction-id': 7949, 'amount': 652},\n",
       "  {'transaction-id': 8382, 'amount': 651},\n",
       "  {'transaction-id': 8898, 'amount': 697},\n",
       "  {'transaction-id': 9166, 'amount': 715},\n",
       "  {'transaction-id': 9835, 'amount': 647}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(js.filter(lambda record: record['name'] == 'Alice')\n",
    "   .pluck('transactions')\n",
    "   .take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:29.501356Z",
     "iopub.status.busy": "2022-04-20T16:12:29.500899Z",
     "iopub.status.idle": "2022-04-20T16:12:29.531128Z",
     "shell.execute_reply": "2022-04-20T16:12:29.530367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'transaction-id': 790, 'amount': 1063},\n",
       " {'transaction-id': 4060, 'amount': 1103},\n",
       " {'transaction-id': 4577, 'amount': 1077})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(js.filter(lambda record: record['name'] == 'Alice')\n",
    "   .pluck('transactions')\n",
    "   .flatten()\n",
    "   .take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:29.534548Z",
     "iopub.status.busy": "2022-04-20T16:12:29.534330Z",
     "iopub.status.idle": "2022-04-20T16:12:29.574745Z",
     "shell.execute_reply": "2022-04-20T16:12:29.573058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1063, 1103, 1077)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(js.filter(lambda record: record['name'] == 'Alice')\n",
    "   .pluck('transactions')\n",
    "   .flatten()\n",
    "   .pluck('amount')\n",
    "   .take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:29.578784Z",
     "iopub.status.busy": "2022-04-20T16:12:29.578101Z",
     "iopub.status.idle": "2022-04-20T16:12:30.136636Z",
     "shell.execute_reply": "2022-04-20T16:12:30.136036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631.7219545104086"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(js.filter(lambda record: record['name'] == 'Alice')\n",
    "   .pluck('transactions')\n",
    "   .flatten()\n",
    "   .pluck('amount')\n",
    "   .mean()\n",
    "   .compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby and Foldby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we want to group data by some function or key.  We can do this either with the `.groupby` method, which is straightforward but forces a full shuffle of the data (expensive) or with the harder-to-use but faster `.foldby` method, which does a streaming combined groupby and reduction.\n",
    "\n",
    "*  `groupby`:  Shuffles data so that all items with the same key are in the same key-value pair\n",
    "*  `foldby`:  Walks through the data accumulating a result per key\n",
    "\n",
    "*Note: the full groupby is particularly bad. In actual workloads you would do well to use `foldby` or switch to `DataFrame`s if possible.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `groupby`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby collects items in your collection so that all items with the same value under some function are collected together into a key-value pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:30.144100Z",
     "iopub.status.busy": "2022-04-20T16:12:30.143328Z",
     "iopub.status.idle": "2022-04-20T16:12:30.285128Z",
     "shell.execute_reply": "2022-04-20T16:12:30.284300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, ['Charlie']), (3, ['Bob', 'Dan']), (5, ['Alice', 'Edith', 'Frank'])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = db.from_sequence(['Alice', 'Bob', 'Charlie', 'Dan', 'Edith', 'Frank'])\n",
    "b.groupby(len).compute()  # names grouped by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:30.289742Z",
     "iopub.status.busy": "2022-04-20T16:12:30.289099Z",
     "iopub.status.idle": "2022-04-20T16:12:30.518519Z",
     "shell.execute_reply": "2022-04-20T16:12:30.516506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [0, 2, 4, 6, 8]), (1, [1, 3, 5, 7, 9])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = db.from_sequence(list(range(10)))\n",
    "b.groupby(lambda x: x % 2).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:30.523076Z",
     "iopub.status.busy": "2022-04-20T16:12:30.522638Z",
     "iopub.status.idle": "2022-04-20T16:12:30.744987Z",
     "shell.execute_reply": "2022-04-20T16:12:30.743694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 8), (1, 9)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.groupby(lambda x: x % 2).starmap(lambda k, v: (k, max(v))).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `foldby`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foldby can be quite odd at first.  It is similar to the following functions from other libraries:\n",
    "\n",
    "*  [`toolz.reduceby`](http://toolz.readthedocs.io/en/latest/streaming-analytics.html#streaming-split-apply-combine)\n",
    "*  [`pyspark.RDD.combineByKey`](http://abshinn.github.io/python/apache-spark/2014/10/11/using-combinebykey-in-apache-spark/)\n",
    "\n",
    "When using `foldby` you provide \n",
    "\n",
    "1.  A key function on which to group elements\n",
    "2.  A binary operator such as you would pass to `reduce` that you use to perform reduction per each group\n",
    "3.  A combine binary operator that can combine the results of two `reduce` calls on different parts of your dataset.\n",
    "\n",
    "Your reduction must be associative.  It will happen in parallel in each of the partitions of your dataset.  Then all of these intermediate results will be combined by the `combine` binary operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:30.750491Z",
     "iopub.status.busy": "2022-04-20T16:12:30.749925Z",
     "iopub.status.idle": "2022-04-20T16:12:30.820666Z",
     "shell.execute_reply": "2022-04-20T16:12:30.819699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 8), (1, 9)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.foldby(lambda x: x % 2, binop=max, combine=max).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with account data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the number of people with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:30.824831Z",
     "iopub.status.busy": "2022-04-20T16:12:30.824424Z",
     "iopub.status.idle": "2022-04-20T16:12:35.935157Z",
     "shell.execute_reply": "2022-04-20T16:12:35.934442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alice', 72), ('Alice', 72), ('Alice', 78), ('Alice', 78), ('Bob', 131), ('Bob', 131), ('Bob', 141), ('Bob', 143), ('Charlie', 96), ('Charlie', 96), ('Charlie', 104), ('Charlie', 104), ('Dan', 36), ('Dan', 36), ('Dan', 39), ('Dan', 39), ('Edith', 133), ('Edith', 135), ('Edith', 145), ('Edith', 146), ('Frank', 135), ('Frank', 137), ('Frank', 146), ('Frank', 149), ('George', 131), ('George', 131), ('George', 142), ('George', 142), ('Hannah', 80), ('Hannah', 81), ('Hannah', 87), ('Hannah', 88), ('Ingrid', 60), ('Ingrid', 60), ('Ingrid', 65), ('Ingrid', 65), ('Jerry', 104), ('Jerry', 104), ('Jerry', 192), ('Kevin', 192), ('Kevin', 192), ('Kevin', 208), ('Kevin', 208), ('Laura', 137), ('Laura', 137), ('Laura', 144), ('Laura', 144), ('Michael', 198), ('Michael', 202), ('Michael', 213), ('Michael', 219), ('Norbert', 126), ('Norbert', 130), ('Norbert', 142), ('Norbert', 143), ('Oliver', 72), ('Oliver', 72), ('Oliver', 78), ('Oliver', 78), ('Patricia', 84), ('Patricia', 84), ('Patricia', 91), ('Patricia', 91), ('Quinn', 96), ('Quinn', 96), ('Quinn', 104), ('Quinn', 104), ('Ray', 117), ('Ray', 119), ('Ray', 128), ('Ray', 129), ('Sarah', 150), ('Sarah', 150), ('Sarah', 162), ('Sarah', 162), ('Tim', 153), ('Tim', 155), ('Tim', 160), ('Tim', 166), ('Ursula', 60), ('Ursula', 60), ('Ursula', 65), ('Ursula', 65), ('Victor', 154), ('Victor', 156), ('Victor', 168), ('Victor', 168), ('Wendy', 162), ('Wendy', 162), ('Wendy', 174), ('Wendy', 176), ('Xavier', 115), ('Xavier', 116), ('Xavier', 124), ('Xavier', 124), ('Yvonne', 57), ('Yvonne', 57), ('Yvonne', 57), ('Yvonne', 64), ('Zelda', 84), ('Zelda', 84), ('Zelda', 91), ('Zelda', 91)]\n",
      "CPU times: user 1.32 s, sys: 104 ms, total: 1.43 s\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Warning, this one takes a while...\n",
    "result = js.groupby(lambda item: item['name']).starmap(lambda k, v: (k, len(v))).compute()\n",
    "print(sorted(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:35.950623Z",
     "iopub.status.busy": "2022-04-20T16:12:35.943619Z",
     "iopub.status.idle": "2022-04-20T16:12:36.519078Z",
     "shell.execute_reply": "2022-04-20T16:12:36.518379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alice', 300), ('Bob', 546), ('Charlie', 400), ('Dan', 150), ('Edith', 559), ('Frank', 567), ('George', 546), ('Hannah', 336), ('Ingrid', 250), ('Jerry', 400), ('Kevin', 800), ('Laura', 562), ('Michael', 832), ('Norbert', 541), ('Oliver', 300), ('Patricia', 350), ('Quinn', 400), ('Ray', 493), ('Sarah', 624), ('Tim', 634), ('Ursula', 250), ('Victor', 646), ('Wendy', 674), ('Xavier', 479), ('Yvonne', 235), ('Zelda', 350)]\n",
      "CPU times: user 146 ms, sys: 20.4 ms, total: 167 ms\n",
      "Wall time: 563 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This one is comparatively fast and produces the same result.\n",
    "from operator import add\n",
    "def incr(tot, _):\n",
    "    return tot + 1\n",
    "\n",
    "result = js.foldby(key='name', \n",
    "                   binop=incr, \n",
    "                   initial=0, \n",
    "                   combine=add, \n",
    "                   combine_initial=0).compute()\n",
    "print(sorted(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: compute total amount per name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to groupby (or foldby) the `name` key, then add up the all of the amounts for each name.\n",
    "\n",
    "Steps\n",
    "\n",
    "1.  Create a small function that, given a dictionary like \n",
    "\n",
    "        {'name': 'Alice', 'transactions': [{'amount': 1, 'id': 123}, {'amount': 2, 'id': 456}]}\n",
    "        \n",
    "    produces the sum of the amounts, e.g. `3`\n",
    "    \n",
    "2.  Slightly change the binary operator of the `foldby` example above so that the binary operator doesn't count the number of entries, but instead accumulates the sum of the amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:36.523059Z",
     "iopub.status.busy": "2022-04-20T16:12:36.522391Z",
     "iopub.status.idle": "2022-04-20T16:12:36.526122Z",
     "shell.execute_reply": "2022-04-20T16:12:36.525551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same reasons that Pandas is often faster than pure Python, `dask.dataframe` can be faster than `dask.bag`.  We will work more with DataFrames later, but from the point of view of a Bag, it is frequently the end-point of the \"messy\" part of data ingestionâ€”once the data can be made into a data-frame, then complex split-apply-combine logic will become much more straight-forward and efficient.\n",
    "\n",
    "You can transform a bag with a simple tuple or flat dictionary structure into a `dask.dataframe` with the `to_dataframe` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:36.529203Z",
     "iopub.status.busy": "2022-04-20T16:12:36.528983Z",
     "iopub.status.idle": "2022-04-20T16:12:37.215620Z",
     "shell.execute_reply": "2022-04-20T16:12:37.214790Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>[{'transaction-id': 6861, 'amount': 206}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>[{'transaction-id': 743, 'amount': 796}, {'tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Norbert</td>\n",
       "      <td>[{'transaction-id': 40, 'amount': 118}, {'tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice</td>\n",
       "      <td>[{'transaction-id': 790, 'amount': 1063}, {'tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>[{'transaction-id': 111, 'amount': 1666}, {'tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     name                                       transactions\n",
       "0   0    Sarah          [{'transaction-id': 6861, 'amount': 206}]\n",
       "1   1    Jerry  [{'transaction-id': 743, 'amount': 796}, {'tra...\n",
       "2   2  Norbert  [{'transaction-id': 40, 'amount': 118}, {'tran...\n",
       "3   3    Alice  [{'transaction-id': 790, 'amount': 1063}, {'tr...\n",
       "4   4    Kevin  [{'transaction-id': 111, 'amount': 1666}, {'tr..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = js.to_dataframe()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now looks like a well-defined DataFrame, and we can apply Pandas-like computations to it efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Dask DataFrame, how long does it take to do our prior computation of numbers of people with the same name?  It turns out that `dask.dataframe.groupby()` beats `dask.bag.groupby()` by more than an order of magnitude; but it still cannot match `dask.bag.foldby()` for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:37.219797Z",
     "iopub.status.busy": "2022-04-20T16:12:37.219430Z",
     "iopub.status.idle": "2022-04-20T16:12:39.001971Z",
     "shell.execute_reply": "2022-04-20T16:12:39.001357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 317 ms, sys: 18.4 ms, total: 336 ms\n",
      "Wall time: 1.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name\n",
       "Alice      300\n",
       "Bob        546\n",
       "Charlie    400\n",
       "Dan        150\n",
       "Edith      559\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df1.groupby('name').id.count().compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame format is less-than-optimal because the `transactions` column is filled with nested data so Pandas has to revert to `object` dtype, which is quite slow in Pandas.  Ideally we want to transform to a dataframe only after we have flattened our data so that each record is a single `int`, `string`, `float`, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:39.007117Z",
     "iopub.status.busy": "2022-04-20T16:12:39.006271Z",
     "iopub.status.idle": "2022-04-20T16:12:39.037962Z",
     "shell.execute_reply": "2022-04-20T16:12:39.037292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 0, 'name': 'Sarah', 'amount': 206, 'transaction-id': 6861},\n",
       " {'id': 1, 'name': 'Jerry', 'amount': 796, 'transaction-id': 743},\n",
       " {'id': 1, 'name': 'Jerry', 'amount': 761, 'transaction-id': 2081})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def denormalize(record):\n",
    "    # returns a list for each person, one item per transaction\n",
    "    return [{'id': record['id'], \n",
    "             'name': record['name'], \n",
    "             'amount': transaction['amount'], \n",
    "             'transaction-id': transaction['transaction-id']}\n",
    "            for transaction in record['transactions']]\n",
    "\n",
    "transactions = js.map(denormalize).flatten()\n",
    "transactions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:39.042236Z",
     "iopub.status.busy": "2022-04-20T16:12:39.041649Z",
     "iopub.status.idle": "2022-04-20T16:12:39.158268Z",
     "shell.execute_reply": "2022-04-20T16:12:39.153711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>206</td>\n",
       "      <td>6861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>796</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>761</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>859</td>\n",
       "      <td>3492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>885</td>\n",
       "      <td>5980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  amount  transaction-id\n",
       "0   0  Sarah     206            6861\n",
       "1   1  Jerry     796             743\n",
       "2   1  Jerry     761            2081\n",
       "3   1  Jerry     859            3492\n",
       "4   1  Jerry     885            5980"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = transactions.to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:39.162173Z",
     "iopub.status.busy": "2022-04-20T16:12:39.161646Z",
     "iopub.status.idle": "2022-04-20T16:12:40.572441Z",
     "shell.execute_reply": "2022-04-20T16:12:40.569732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 245 ms, sys: 28.6 ms, total: 273 ms\n",
      "Wall time: 1.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name\n",
       "Alice       10376\n",
       "Bob         23426\n",
       "Charlie      9919\n",
       "Dan         11284\n",
       "Edith       28034\n",
       "Frank       26033\n",
       "George      18396\n",
       "Hannah      19748\n",
       "Ingrid       4093\n",
       "Jerry       18032\n",
       "Kevin       27374\n",
       "Laura       17074\n",
       "Michael     23899\n",
       "Norbert     19588\n",
       "Oliver      14376\n",
       "Patricia     8771\n",
       "Quinn       18084\n",
       "Ray         16059\n",
       "Sarah       29550\n",
       "Tim         23012\n",
       "Ursula      21738\n",
       "Victor      25341\n",
       "Wendy       45305\n",
       "Xavier      20210\n",
       "Yvonne       9298\n",
       "Zelda       10980\n",
       "Name: transaction-id, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# number of transactions per name\n",
    "# note that the time here includes the data load and ingestion\n",
    "df.groupby('name')['transaction-id'].count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bags provide very general computation (any Python function.)  This generality\n",
    "comes at cost.  Bags have the following known limitations\n",
    "\n",
    "1.  Bag operations tend to be slower than array/dataframe computations in the\n",
    "    same way that Python tends to be slower than NumPy/Pandas\n",
    "2.  ``Bag.groupby`` is slow.  You should try to use ``Bag.foldby`` if possible.\n",
    "    Using ``Bag.foldby`` requires more thought. Even better, consider creating\n",
    "    a normalised dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn More\n",
    "\n",
    "* [Bag documentation](https://docs.dask.org/en/latest/bag.html)\n",
    "* [Bag screencast](https://youtu.be/-qIiJ1XtSv0)\n",
    "* [Bag API](https://docs.dask.org/en/latest/bag-api.html)\n",
    "* [Bag examples](https://examples.dask.org/bag.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T16:12:40.577541Z",
     "iopub.status.busy": "2022-04-20T16:12:40.576760Z",
     "iopub.status.idle": "2022-04-20T16:12:41.254032Z",
     "shell.execute_reply": "2022-04-20T16:12:41.253126Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/usr/share/miniconda3/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
