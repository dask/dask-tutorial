{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/fail-case.gif\" width=40% align=\"right\">\n",
    "\n",
    "Foundations\n",
    "===========\n",
    "\n",
    "*Dask is a way to represent computations as dictionaries, and then analyze and execute them.*\n",
    "\n",
    "Dask supports parallel computing.  Internally it executes graphs of tasks with data dependencies.  In this section we talk about what these graphs look like and how to construct them.  We finish with exercises manually building graphs that use basic Pandas functionality.  This is straightforward but somewhat tedious.  We'll automate it in future sections.\n",
    "\n",
    "You can safely skip this section if you don't care about how dask works internally.\n",
    "\n",
    "**Related Documentation**\n",
    "\n",
    "*  [Dask graph specification](http://dask.pydata.org/en/latest/spec.html)\n",
    "*  [Discussion on custom graphs](http://dask.pydata.org/en/latest/custom-graphs.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Programming\n",
    "\n",
    "Normally we write functions and then use those function in linear code.  The Python interpreter executes this code from the top down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call functions in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = inc(a)\n",
    "\n",
    "x = 10\n",
    "y = inc(x)\n",
    "\n",
    "z = add(b, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though some of this work could have happened in parallel Python went ahead and executed one line after the other.\n",
    "\n",
    "If we want to execute code in parallel then we need to stop Python from taking control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation as a data structure\n",
    "\n",
    "Instead of writing normal code we store the steps of the computation above as a Python dictionary where each function call becomes a Python tuple.\n",
    "\n",
    "This is going to look a little strange but we'll have the entire computation stored in a Python data structure that we can manipulate with *other* Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsk = {'a': 1, \n",
    "       'b': (inc, 'a'),\n",
    "       \n",
    "       'x': 10,\n",
    "       'y': (inc, 'x'),\n",
    "       \n",
    "       'z': (add, 'b', 'y')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(dsk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call a dictionary that looks like this a *dask graph*.  A dask graph is just a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Approaches to Delayed Evaluation\n",
    "\n",
    "Representing Python functions as tuples containing function names and arguments may seem strange, but in reality you are already familiar with the style.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sometimes we defer compuations with a lambda\n",
    "\n",
    "x = 15\n",
    "y = 30\n",
    "z = lambda: x + y\n",
    "\n",
    "# z delays the execution of x + y until we call z()\n",
    "# This is very similar to (add, 'x', 'y')\n",
    "\n",
    "# Sometimes we defer computations with strings\n",
    "\n",
    "z = \"x + y\"\n",
    "print eval(z)\n",
    "\n",
    "# The variable 'z' stores a string that is a valid Python statement\n",
    "# We call eval to fully evaluate `z' and obtain the answer.\n",
    "\n",
    "# Sometimes we use functools.partial\n",
    "import functools\n",
    "z = functools.partial(add, x, y)\n",
    "\n",
    "# Dask delays evaluation with tuples\n",
    "z = (add, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: further define dask graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute dask graphs\n",
    "\n",
    "The dask library contains functions to execute these dictionaries in parallel with multiple threads or multiple processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.threaded import get\n",
    "get(dsk, 'z')  # Execute in multiple threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.multiprocessing import get\n",
    "get(dsk, 'z')  # Execute in multiple processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as long as you're willing to write code in this funny way with dictionaries, dask will run your separate functions in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and Visualize Graphs\n",
    "\n",
    "Because our computation is just a dictionary we can write arbitrary functions to do a variety of useful analyses on these dictionaries.  A simple yet common operation is just to visualize the computation as a visual graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Requires that you have pydot and graphviz installed\n",
    "# This isn't a problem if this doesn't work for you\n",
    "from dask.dot import dot_graph\n",
    "dot_graph(dsk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it\n",
    "----------\n",
    "\n",
    "The rest of this tutorial is fancy ways to construct and executing dask graphs.  We won't make any more by hand after this notebook.  If you'd like to learn more, read the [dask graph spec](http://dask.pydata.org/en/latest/spec.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - `read_csv`\n",
    "------------------------\n",
    "\n",
    "As an exercise we'll parallelize some basic Pandas code by rewriting it as a dask graph.  This will be a little tedious but should give us speedups right away.  In future sections we'll learn how dask submodules like `dask.dataframe` automate this work for us.\n",
    "\n",
    "There are three CSV files in your `data` directory.   We count how many rows are in all of these csv files total.  In normal Python we solve this problem in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "filenames = [os.path.join('data', 'accounts.%d.csv' % i) for i in [0, 1, 2]]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(filenames[0], nrows=5)  # a sample of the first file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "a = pd.read_csv(filenames[0])\n",
    "b = pd.read_csv(filenames[1])\n",
    "c = pd.read_csv(filenames[2])\n",
    "\n",
    "na = len(a)\n",
    "nb = len(b)\n",
    "nc = len(c)\n",
    "\n",
    "total = sum([na, nb, nc])\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a dask graph/dictionary for this computation\n",
    "\n",
    "Just as we turned code that looks like \n",
    "\n",
    "```python\n",
    "y = f(x)\n",
    "```\n",
    "\n",
    "into dictionaries like \n",
    "\n",
    "```python\n",
    "{'y': (f, 'x')}\n",
    "```\n",
    "\n",
    "We can transform the above calls to `pd.read_csv`, `len`, and `sum` into a dictionary of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsk = {'a': (pd.read_csv, filenames[0]),\n",
    "       'b': ...,\n",
    "       ...\n",
    "       'total': ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "%load solutions/Foundations-01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute your dask graph\n",
    "\n",
    "We execute dask graphs with the `get` functions.  There is a get function for both multi-threading and multi-processing.  Get takes two arguments\n",
    "\n",
    "    get(dsk, output_key)\n",
    "\n",
    "Run the following cells and see how each get function performs.  Why is there a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.threaded import get\n",
    "%time get(dsk, 'total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.multiprocessing import get\n",
    "%time get(dsk, 'total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Sum of amounts\n",
    "\n",
    "As a slightly more complex example we'll compute the sum of the amounts column in each CSV file and then add up these sums to get the total amount over all CSV files.\n",
    "\n",
    "To make the graph construction slightly more challenging we'll use Python for loops rather than write out every entry by hand.\n",
    "\n",
    "In normal sequential code we might execute the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sums = list()\n",
    "for fn in filenames:\n",
    "    df = pd.read_csv(fn)\n",
    "    sums.append(df.amount.sum())\n",
    "total = sum(sums)\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the same computation as a dask graph.\n",
    "\n",
    "We suggest building and using a small function to compute the sum of the amount of a dataframe and using this function in your dask graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def amount_sum(df):\n",
    "    return df.amount.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dsk = dict()\n",
    "\n",
    "for fn in filenames:\n",
    "    dsk[...] = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "%load solutions/Foundations-02.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get(dsk, 'total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "------------\n",
    "\n",
    "We've learned about how dask graph represent computations and how we can execute these computations with dask schedulers / get functions.  We've made a few of these dictionaries by hand.  It's straightforward but perhaps tiresome.\n",
    "\n",
    "In the next sections we'll play with systems that generate these dictionaries for us."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
